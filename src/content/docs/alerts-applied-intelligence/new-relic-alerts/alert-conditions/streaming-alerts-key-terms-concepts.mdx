---
title: 'Streaming alerts: key terms and concepts'
tags:
  - Alerts and applied intelligence
  - Alerts
  - Get started
redirects:
  - /docs/alerts-applied-intelligence/new-relic-alerts/get-started/streaming-alerts-key-terms-concepts
  - /docs/alerts-applied-intelligence/new-relic-alerts/advanced-alerts/understand-technical-concepts/streaming-alerts-key-terms-concepts/
---

import accountsStreamingAlertsAggregationFlowchart from 'images/accounts_diagram_streaming-alerts-aggregation-flowchart.webp'

import accountsStreamingAlerts from 'images/accounts_diagram_streaming-alerts.webp'

import alertsFineTuneYourSignal from 'images/alerts-screenshot-crop_fine-tune-your-signal.webp'

import alertsSetConditionThresholds from 'images/alerts-screenshot-crop_set-condition-thresholds.webp'

The streaming alerts platform checks for incidents based on data that's present or missing in your stream of data, or [signal](/docs/new-relic-solutions/get-started/glossary/#signal), coming into New Relic.

You can use [NRQL conditions](/docs/alerts-applied-intelligence/new-relic-alerts/alert-conditions/nrql-alert-conditions) to control what part of the signal you want to be notified about. Your NRQL condition filters the data that's processed by the [streaming algorithm](/docs/new-relic-solutions/get-started/glossary/#streaming-algorithm).

## Why it matters [#why]

Understanding how streaming alerts works will help you fine-tune your NRQL conditions to be notified about what's important to you.

<img
  title="A diagram that demonstrates how data is streamed into New Relic."
  alt="A diagram that demonstrates how data is streamed into New Relic."
  src={accountsStreamingAlerts}
/>

<figcaption>
  Only data that matches the conditions of the NRQL WHERE clause is alerted on. For more details on each step of the process, see [Streaming alerts process and descriptions](#streaming-table).
</figcaption>

As data streams into New Relic, it's filtered by the NRQL condition. Before data is evaluated, it must meet the criteria defined by the [NRQL query's `WHERE` clause](/docs/query-your-data/nrql-new-relic-query-language/get-started/nrql-syntax-clauses-functions#sel-where). Instead of evaluating that data immediately for incidents, the NRQL alert conditions collect the data over a period of time known as the aggregation window. An additional delay/timer allows for slower data points to arrive before the window is aggregated.

Once the delay/timer time has elapsed, New Relic aggregates the data into a single data point. Alerts then compares the data point to the condition's threshold criteria to determine whether an incident should be opened.

Even if a data point meets the criteria for an incident, an incident may not be opened. An incident is only opened when data points consistently meet the threshold criteria over a period of time. This is the threshold duration. If the data points exceed for an entire threshold duration, you'll receive a notification based on your policy settings.

All of these configurable delays give you more control over how you're alerted on sporadic and missing data.

## Streaming alerts process and descriptions [#streaming-table]

<table class="alternate">
  <thead>
    <tr>
      <th style={{ width: "200px" }}>
        Process
      </th>

      <th>
        **Description**
      </th>
    </tr>
  </thead>

  <tbody>
    <tr>
      <td>
        Streaming data
      </td>

      <td>
        All data coming into New Relic.
      </td>
    </tr>

    <tr>
      <td>
        WHERE clause
      </td>

      <td>
        Filters all incoming streaming data. We only monitor for alerts on data that makes it through this filter.
      </td>
    </tr>

    <tr>
      <td>
        Aggregation methods
      </td>

      <td>
        One of three methods that control how data is collected before it's evaluated.

        They are:

        * Event flow (Default)
        * Event timer
        * Cadence
      </td>
    </tr>

    <tr>
      <td>
        Aggregation window
      </td>

      <td>
        Data with timestamps that fall within this window will be aggregated and then evaluated.
      </td>
    </tr>

    <tr>
      <td>
        Sliding windows
      </td>

      <td>
        When enabled, it causes aggregation windows to overlap, creating smoother charts.

        Use the sliding windows duration to set the amount of time your aggregation windows overlap.
      </td>
    </tr>

    <tr>
      <td>
        Delay/timer
      </td>

      <td>
        A time delay to ensure all data points have arrived in the aggregation window before aggregation occurs.
      </td>
    </tr>

    <tr>
      <td>
        Aggregated data
      </td>

      <td>
        Data in the aggregated window is collapsed to a single data point for alert evaluation.
      </td>
    </tr>

    <tr>
      <td>
        Evaluation
      </td>

      <td>
        The data point is evaluated by the NRQL condition, which is trigged by each incoming aggregated data point.
      </td>
    </tr>

    <tr>
      <td>
        Threshold duration
      </td>

      <td>
        A specific duration that determines if an incident is created. If your specified NRQL condition meets the threshold criteria over the threshold duration, an incident occurs.

        When a data point lacks data, a custom value is inserted to fill the gap.
      </td>
    </tr>
  </tbody>
</table>

## Choose your aggregation method [#choose-aggregation-method]

Check this flowchart to help you decide what aggregation method you should use.

If your data arrives consistently and predictably, use **[event flow](#event-flow)**. If your data arrives inconsistently and unpredictably, use **[event timer](#event-timer)**.

<img
      width="40%;"
      title="Choose your aggregation method."
      alt="Choose your aggregation method."
      src={accountsStreamingAlertsAggregationFlowchart}
    />

## Advanced signal settings [#advanced-signal]

When creating a condition, there are several advanced signal settings.

<img
  width="50%;"
  title="Screenshot showing the advanced signal settings"
  alt="Screenshot showing the advanced signal settings"
  src={alertsFineTuneYourSignal}
/>

<figcaption>
  Advanced signal settings in the creation of an alarm condition. Go to **[one.newrelic.com > All capabilities](https://one.newrelic.com/all-capabilities) > Alerts & AI > Alert conditions**, then **+ New alert condition**.
</figcaption>

Below are instructions and tips on how to configure them.

<CollapserGroup>
<Collapser
    id="window-duration"
    title="Aggregation window duration"
    >

Customize aggregation windows to the duration that you need to make loss of signal detection more effective and to reduce unnecessary notifications.

An aggregation window is a specific block of time. We gather data points together in an aggregation window, before evaluating the data. A longer aggregation window can smooth out the data, since an outlier data point will have more data points to be aggregated with, giving it less of an influence on the aggregated data point that is sent for evaluation. When a data point arrives, its timestamp is used to put it in the proper aggregation window.

You can set the aggregation window duration to choose how long data is accumulated in a streaming time window before it's aggregated. 

You can set your aggregation window to anything between **30 seconds** and **2 hours**. The default is **1 minute**.

</Collapser>

<Collapser
    id="sliding-window-aggregation"
    title="Sliding window aggregation"
    >

You can use [sliding windows](/docs/query-your-data/nrql-new-relic-query-language/nrql-query-tutorials/create-smoother-charts-sliding-windows) to create smoother charts. This is done by creating overlapping windows of data.

Once enabled, set the "slide by interval" to control how much overlap time your aggregated windows have. The interval must be shorter than the aggregation window while also dividing evenly into it.

<Callout variant="important">
  Immediately after you create a new sliding windows alert condition or perform any action that can cause an [evaluation reset](#evaluation-resets), your condition will need time build up an "aggregated buffer" for the duration of the first aggregation window. During that time, no incidents will trigger. Once that single aggregation window has passed, a complete "buffer" will have been built and the condition will function normally.
</Callout>

</Collapser>

<Collapser
    id="streaming"
    title="Streaming method"
    >

Choose between these streaming aggregation methods to get the best evaluation results for your conditions.

## Event flow (default) [#event-flow]

Event flow aggregates a window of data when the first data point arrives in a subsequent window. The custom delay defines which subsequent window data will start to populate to trigger aggregation of the current window. A custom delay provides extra time for data to arrive. These times are based on the data's timestamps and not New Relic's wall clock time.

For example, suppose you're monitoring CPU usage in window durations of 1 minute and a 3 minute delay.

When a CPU usage data point comes in with a timestamp between 12:00pm and 12:01pm, event flow will not aggregate that window until a data point shows up with a timestamp between 12:04pm and 12:05pm. When event flow receives the first data point with a timestamp of 12:04pm or later, it sends the 12:00 to 12:01 data to be aggregated.

<Callout variant="caution">
  If you expect your data points to arrive more than 65 minutes apart, please use the Event Timer method described below.
</Callout>

## Event timer [#event-timer]

Like event flow, event timer will only aggregate data for a given window when data arrives for that window. When a data point arrives for an aggregation window, a timer dedicated to that window starts to count down. If no further data arrives before the timer counts down, the data for that window is aggregated. If more data points arrive before the timer has completed counting down, the timer is reset.

For example, suppose you're monitoring CloudWatch data that arrives fairly infrequently. You're using a window duration of 1 minute and a 3 minute timer.

When a CloudWatch data point comes in with a timestamp between 12:00pm and 12:01pm, the timer will start to count down. If no further data points show up for that 12:00-12:01 window, the window will get aggregated 3 minutes later.

If a new data point with a timestamp between 12:00 and 12:01 arrives, the timer resets. It keeps resetting every time more data points for that window arrive. The window will not be sent for aggregation until the timer reaches 0.

If the timer for a later data point elapses before an earlier data point, the event timer method waits for the earlier timer to elapse before aggregating the later data point.

For best results, make sure your timer is equal to or longer than your window duration time. If the timer is less than your window duration and your data flow is inconsistent, then your data may be evaluated before all of your data points arrive. This could cause you to be notified incorrectly.

## Cadence [#cadence]

We recommend you use one of the other two methods.

Cadence is our old streaming aggregation method. This method uses New Relic's wall clock time to determine when data is aggregated and evaluated. It doesn't take into account data point timestamps as they arrive.

</Collapser>

<Collapser
    id="delay-timer"
    title="Delay"
    >

You can adjust the delay/timer to coordinate [our streaming alerting algorithm](/docs/new-relic-solutions/get-started/glossary/#streaming-algorithm) with your data's behavior. If your data is sparse or inconsistent, you may want to use the event timer aggregation method.

For the cadence method, the total supported latency is the sum of the aggregation window duration and the delay.

If the data type comes from an [APM language agent](/docs/apm/new-relic-apm/getting-started/introduction-apm) and is aggregated from many app instances (for example, `Transactions`, `TransactionErrors`, etc.), we recommend using the event flow method with the default settings.

<Callout variant="important">
  When creating NRQL conditions for data collected from [Infrastructure Cloud Integrations](/docs/infrastructure/infrastructure-integrations/get-started/introduction-infrastructure-integrations/#cloud) such as AWS CloudWatch or Azure, we recommend that you use the event timer method.
</Callout>

</Collapser>

<Collapser
    id="data-gaps"
    title="Gag filling strategy"
    >

Gap filling lets you customize the values to use when your signals don't have any data. You can fill gaps in your data streams with one of these settings:

* **None**: (Default) Choose this if you don't want to take any action on empty aggregation windows. On evaluation, an empty aggregation window will reset the threshold duration timer. For example, if a condition says that all aggregation windows must have data points above the threshold for 5 minutes, and 1 of the 5 aggregation windows is empty, then the condition won't be an incident.
* **Custom static value**: Choose this if you'd like to insert a custom static value into the empty aggregation windows before they're evaluated. This option has an additional, required parameter of `fillValue` (as named in the API) that specifies what static value should be used. This defaults to `0`.
* **Last known value**: This option inserts the last seen value before evaluation occurs. We maintain the state of the last seen value for a minimum of 2 hours. If the configured threshold duration is longer than 2 hours, this value is kept for that duration instead.

<Callout variant="tip">
  The alerts system fills gaps in actively reported signals. This signal history is dropped after a period of inactivity and, for gap filling, data points received after this period of inactivity are treated as new signals. The inactivity length is either 2 hours or the configured threshold duration, whichever is longer.

  To learn more about signal loss, gap filling, and how to request access to these features, see [this Support Forum post](https://discuss.newrelic.com/t/announcing-new-relic-one-streaming-alerts-for-nrql-conditions/115361).
</Callout>

Options for editing data gap settings:

* In the NRQL conditions UI, go to **Condition settings > Advanced signal settings > fill data gaps with** and choose an option.
* If using our [Nerdgraph API](/docs/apis/nerdgraph/examples/nerdgraph-api-loss-signal-gap-filling/) (preferred), this node is located at:
  `actor : account : alerts : nrqlCondition : signal : fillOption | fillValue`
* NerdGraph is our recommended API for this but if you're using our REST API, you can find this setting in the REST API explorer under the **"signal"** section of [the Alert NRQL conditions API](https://api.newrelic.com/docs/#/Alerts%20NRQL%20Conditions).

</Collapser>

<Collapser
    id="evaluation-delay"
    title="Evaluation delay"
    >

You can enable the `Use evaluation delay` flag and set up to 120 minutes to delay the evalution of incoming signals.

When new entities are first deployed, resource utilization on the entity is often unusually high. In autoscale environments this can easily create a lot of false alerts. By delaying the start of alert detection on signals emitted from new entities you can significantly reduce the number of false alarms associated with deployments in orchestrated or autoscale environments.

Options to enable evaluation delay:

* In the NRQL conditions UI, go to **Adjust to signal behavior > Use evaluation delay**.
* If using our [Nerdgraph API](/docs/apis/nerdgraph/examples/nerdgraph-api-nrql-condition-alerts/#static-condition), this node is located at:
  `actor : account : alerts : nrqlCondition : signal : evaluationDelay`

</Collapser>
</CollapserGroup>

## Set condition thresholds [#signal-loss]

Loss of signal occurs when no data matches the NRQL condition over a specific period of time. You can set your loss of signal threshold duration and also what happens when the threshold is crossed.

<Callout variant="important">
  The loss of signal feature requires a signal to be present before it can detect that the signal is lost. If you enable a condition while a signal is not present, no loss of signal will be detected and the loss of signal feature will not activate.
</Callout>

<img
  width="50%;"
  title="Screenshot showing the set condition thresholds settings"
  alt="Screenshot showing the set condition thresholds settings"
  src={alertsSetConditionThresholds}
/>

<figcaption>
  Set condition thresholds settings in the creation of an alarm condition. Go to **[one.newrelic.com > All capabilities](https://one.newrelic.com/all-capabilities) > Alerts & AI > Alert conditions**, then **+ New alert condition**.
</figcaption>

You may also manage these settings using the GraphQL API (recommended), or the REST API. Go here for specific [GraphQL API examples](//docs/apis/nerdgraph/examples/nerdgraph-api-loss-signal-gap-filling/).

**Loss of signal settings:**

Loss of signal settings include a time duration and two possible actions.

* **Signal loss expiration time**
  * UI label: **Consider the signal lost after**
  * GraphQL Node: [expiration.expirationDuration](/docs/apis/nerdgraph/examples/nerdgraph-api-loss-signal-gap-filling/#loss-of-signal)
  * Expiration duration is a timer that starts and resets when we receive a data point in the streaming alerts pipeline. If we don't receive another data point before your 'expiration time' expires, we consider that signal to be lost. This can be because no data is being sent to New Relic or the `WHERE` clause of your NRQL query is filtering that data out before it is streamed to the alerts pipeline. Note that when you have a faceted query, each facet is a signal. So if any one of those signals ends during the duration specified, that will be considered a loss of signal.
  * The loss of signal expiration time is independent of the threshold duration and triggers as soon as the timer expires.
  * The maximum expiration duration is 48 hours. This is helpful when monitoring for the execution of infrequent jobs. The minimum is 30 seconds, but we recommend using at least 3-5 minutes.
* **Loss of signal actions**
  Once a signal is considered lost, you can close all current open incidents, open new "lost signal" incident, or both.
  * Close all current open incidents: This closes all open incidents that are related to a specific signal. It won't necessarily close all incidents for a condition. If you're alerting on an ephemeral service, or on a sporadic signal, you'll want to choose this action to ensure that incidents are closed properly. The GraphQL node name for this is ["closeViolationsOnExpiration](/docs/apis/nerdgraph/examples/nerdgraph-api-loss-signal-gap-filling/#loss-of-signal)"
  * Open new "lost signal" incident: This will open a new incident when the signal is considered lost. These incidents will indicate that they are due to a loss of signal. Based on your incident preferences, this should trigger a notification. The graphQL node name for this is ["openViolationOnExpiration](/docs/apis/nerdgraph/examples/nerdgraph-api-loss-signal-gap-filling/#loss-of-signal)"
  * When you enable both actions, we'll close all open incidents first, and then open a new incident for loss of signal.

Incidents open due to loss of signal close when:

* the signal comes back. Newly opened lost signal incidents will close immediately when new data is evaluated.
* the condition they belong to expires. By default, conditions expire after 3 days.
* you manually close the incident with the **Close all current open incidents** option.

<Callout variant="tip">
  Loss of signal detection doesn't work on NRQL queries that use nested aggregation or sub-queries.
</Callout>

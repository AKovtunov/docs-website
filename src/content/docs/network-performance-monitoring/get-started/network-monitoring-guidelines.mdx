---
title: Network monitoring guidelines for KTranslate containers
tags:
  - Network monitoring
  - Guidelines
translate:
  - kr
  - jp
metaDescription: Review guidelines for monitoring KTranslate containers.
---

import networkCommonArchitecture from 'images/network_diagram_common-architecture.webp'

In network monitoring, New Relic utilizes [KTranslate containers](https://github.com/kentik/ktranslate) to collect network telemetry data, which can be used to monitor network performance, identify bottlenecks, and troubleshoot problems.

Learn best practices for deploying the KTranslate container, along with architectural and deployment considerations. The guidance is based on the recommendations of subject matter experts and common patterns of deployment used by customers in production environments.

## Deployment considerations [#deployment-considerations]

For the purposes of this document, we will be referencing an architecture that covers the following requirements:

* SNMP polling and SNMP Traps collection
* Syslog collection from network devices
* Network Flow collection in NetFlow v5, NetFlow v9, IPFIX, and sFlow protocols
* Support for multiple sites separated by large distance, geographically

## Common architecture [#common-architecture]

<SideBySide>

  <Side>
    This diagram reflects common networking architecture with the following:

* **DC_01 (AMER)**: 
    * Three containers on one host serving the DC_01 location in New York City.
    * Containers process SNMP polling, NetFlow v5 collection, and Syslog collection
* **OFFICE_01 (APJ)**:
    * One container on one host serving the OFFICE_01 location in Sydney, Australia. 
    * Container processes SNMP polling and SNMP Trap collection
* **DC_02 (EMEA)**:
    * Three containers on one host serving the DC_02 location in Dublin, Ireland. 
    * Containers process NetFlow v9, IPFIX, and sFlow collection

  </Side>
  <Side>
    <img
    title="Common network architecture diagram"
    alt="Diagram to visualize common network architecture"
    src={networkCommonArchitecture}
    width="80%"
    height="80%"
/>
  </Side>
</SideBySide>

## Architectural considerations [#archictural-considerations]

### A container's task

There are some basic rules around what an individual container is capable of doing which are the main drivers when designing network deployment:

* Containers that collect SNMP data can also receive SNMP traps by default.
* Containers that receive Syslog data should run on their own.
* Containers that receive network flow data must be isolated based on the type of flow template being collected.

### Network Flow and Syslog containers [#about-containers]

Technically speaking, there is no requirement for a custom configuration file when using one of these containers. The default from the container image will work fine because all of the container settings are placed by flags at runtime. 

However, without a configuration file with entries in the devices section, the results sent to New Relic APIs will use `device_name` entries resolved via DNS from the IP address in the respective packet. There is support for providing a custom DNS server location at runtime, but full control with tagging is generally accomplished by providing your own entries with the `flow_only` setting set to `true`. Administrators will generally want to control this name so it aligns with the name sent in from SNMP polling the same device.

### Geography [#geography]

SNMP as a protocol, along with ICMP for ping, are generally deprioritized in modern networks. Additionally, SNMP is a UDP protocol that is sensitive to extended latency for round trip times. Care must be taken to create containers close to their target devices to protect from failed polling scenarios.

### Compute scale [#compute-scale]

The individual containers deployed with the KTranslate image are usually hosted on very small hosts and have minimal requirements as outlined in [our documentation](/docs/network-performance-monitoring/advanced/ktranslate-container-management/#container-requirements). However scaling this host’s CPU may be required in heavy polling scenarios. The primary motivator for scaling to a larger CPU footprint for a container is the amount of load presented to the task. In these situations it is normally better to run multiple containers to load balance instead of increasing the total size of your Docker host, which has underlying cost implications.

### Summary [#summary]

In the [common architecture example](#common-architecture) above, the following architectural considerations are in place:

* Each geographical location has its own local containers used to collect and forward data to New Relic.
* DC_01 has three containers:

    * Container 1: SNMP polling
    * Container 2: NetFlow v5 collection
    * Container 3: Syslog collection

    <Callout variant="tip" title="Recommendation">
    In DC_01 there is a Class B private subnet (/16). Care needs to be taken to split up discovery targets into manageable subnet sizes to ensure the job has time to complete.
    </Callout>

* OFFICE_01 uses a single container for SNMP polling with discovery against a /24 subnet.

* DC_02 has three containers, all dedicated to different templates in network flow collection:

    * Container 1: NetFlow v9
    * Container 2: IPFIX
    * Container 3: sFlow

    <Callout variant="tip" title="Recommendation">
    In DC_02, there is an even larger Class A private subnet (/8); however, since there is no need for a discovery in this location there are no concerns about scaling the jobs. Depending on flows-per-second, there may be a need in the future to scale out into additional containers. In a situation like this, you simply need to configure your network flow exporters to target different ports on the Docker host.
    </Callout>

Recommendations below will reference this sample networking architecture.

## Maintaining your deployment [#maintaining-deployment]

After initial installation, there are various techniques that are used to maintain the network monitoring observability footprint. Integrating configuration file changes with tools like Ansible are common, as is building GitOps pipelines around the architecture to support versioning and “guest” options where external teams can submit changes for review.

The most common need for ongoing maintenance is in keeping the list of target devices accurate. There are three main discovery methods to update target devices: 

<CollapserGroup>
<Collapser
    id="automatic-discovery"
    title="Automatic discovery (preferred)"
>
Automatic discovery is the process used by KTranslate to scan a target list of IP addresses and/or ranges, perform a liveness probe, and then run a basic SNMP walk of the MIB-2 System MIB to attempt matching the device to a known SNMP profile.

The container has embedded container runtime flags (`-snmp_discovery_min` and `-snmp_discovery_on_start`) that allow you to build a schedule of recurring SNMP discovery events. This automates discovery jobs against the targets from the `discovery` section in the configuration file, and then automatically updates the file with new devices and refreshes the service to accept the changes.

### Things to consider

Evaluate the pros and cons below to see if this discovery method is right for you.

<table>
    <thead>
        <tr>
            <th>
                Pros
            </th>
            <th>
                Cons
            </th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>
                * Hands-off discovery for known IP ranges and SNMP community strings.
                * Automated correlation to the proper SNMP profile for each device.
                * Safety mechanisms are in place to prevent improper settings that could break your configuration file.
            </td>
            <td>
                * Requires a pre-existing target list of IP addresses and SNMP community strings/V3 authentication in the discovery section of the configuration file.
                * Large subnets are at risk of timeouts (we recommend /16 and above).
                * Teams that make use of device-specific user_tags in their configuration files will have extra work to ensure new devices have their tags updated.
            </td>
        </tr>
    </tbody>
</table>

### How to use this method [#how-to]

This is the native configuration pattern found if you follow the guided installation through the New Relic UI. 

Here's an example configuration file:

```yml
devices: {}
trap:
  listen: '0.0.0.0:1620'
discovery:
  cidrs:
    - 192.168.0.0/24
  ignore_list: []
  debug: false
  ports:
    - 161
  default_communities:
    - public
  default_v3: null
  add_devices: true
  add_mibs: true
  threads: 4
  replace_devices: true
  check_all_ips: true
  use_snmp_v1: false
global:
  poll_time_sec: 300
  mib_profile_dir: /etc/ktranslate/profiles
  mibs_enabled:
    - IF-MIB
  timeout_ms: 3000
  retries: 0
```

Your associated Docker run command would look like this, replacing `$NR_LICENSE_KEY` and `$NR_ACCOUNT_ID`:

```yml
docker run -d --name ktranslate-nr-office01-snmp --restart unless-stopped --pull=always -p 162:1620/udp \
-v `pwd`/snmp-base.yaml:/snmp-base.yaml \
-e NEW_RELIC_API_KEY=$NR_LICENSE_KEY \
kentik/ktranslate:v2 \
  -snmp /snmp-base.yaml \
  -nr_account_id=$NR_ACCOUNT_ID \
  -metrics=jchf \
  -tee_logs=true \
  -service_name=nr-office01-snmp \
  -snmp_discovery_on_start=true \
  -snmp_discovery_min=180 \
  nr1.snmp
```
</Collapser>

<Collapser
    id="manual-discover"
    title="Manual discovery"
>
Manual discovery uses the same mechanism as automated discovery, but it gives you more control. With manual discovery, you can run a bespoke container ad hoc, which means that you can run it whenever you want and you can review and manipulate the results as needed. This is the preferred method for environments where tagging is prevalent or where there is a good amount of control from a centralized team adding new devices to the network. This reduces the need for full subnet scanning, which can be time-consuming and disruptive.

### Things to consider

Evaluate the pros and cons below to see if this discovery method is right for you.

<table>
    <thead>
        <tr>
            <th>
                Pros
            </th>
            <th>
                Cons
            </th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>
                * Full control over the targets and results, including tag decoration.
                * Helps to prevent possible devices that are not in scope for your monitoring footprint.
                * Automated correlation to the proper SNMP profile for each device.
                * Safety mechanisms are in place to prevent improper settings that could break your configuration file.

            </td>
            <td>
                * An administrator must run the container on demand, and from the same Docker host that your production container runs on to ensure network/SNMP connectivity is tested properly.
                * Moving the results from the discovery into the production configuration file is a manual process that requires a restart of the production container in order to load the new settings.

            </td>
        </tr>
    </tbody>
</table>

### How to use this method

This discovery method follows the original deployment option for KTranslate, with the [steps outlined in our documentation](/docs/network-performance-monitoring/setup-performance-monitoring/snmp-performance-monitoring/#manual-container-setup). At a high level, the discovery process is:

1. Pull the latest version of the Docker image to your local machine.
2. Copy the sample `snmp-base.yaml` configuration file from the image to your local machine.
3. Edit the configuration file to update the `discovery` section with the settings you need for `cidrs` and `default_communities`.
4. Launch a short-lived container executing an ad-hoc discovery job.
5. Edit any changes needed to the resulting devices in your configuration file.
6. Copy the new devices from your discovery configuration file into the production container configuration file.
7. Restart your production container to load the new settings.

</Collapser>

<Collapser
    id="manual-device-addition"
    title="Manual device addition"
>
    The last option is to skip the entire discovery process and manually add devices directly into the production configuration file. In practice, it is fairly rare to see this pattern in use as the standard discovery options automatically match devices to their profiles, and ensure that your configuration file is formatted correctly. 

### Things to consider

Evaluate the pros and cons below to see if this discovery method is right for you.

<table>
    <thead>
        <tr>
            <th>
                Pros
            </th>
            <th>
                Cons
            </th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>
                * Full control over the configuration of devices and their tag decorations.

            </td>
            <td>
                * Medium risk of misconfiguration in the settings. This method requires that you know the System Object Identifier (SysOID) of the device as well as understand the profile the device would target so you can identify which MIBs you want enabled (all of this is automated in discovery).
                * Still requires a restart of the production container to load the new settings.

            </td>
        </tr>
    </tbody>
</table>

### How to use this method

Here's an example of the device settings needed to successfully monitor an APC UPS:

```yml
devices:
 ups_snmpv2c__10.10.0.201:
   device_name: ups_snmpv2c
   device_ip: 10.10.0.201
   snmp_comm: public
   oid: .1.3.6.1.4.1.318.1.3.27
   mib_profile: apc_ups.yml
   provider: kentik-ups
   user_tags:
     owning_team: dc_ops
...
global:
  ...
  mibs_enabled:
  - ARISTA-BGP4V2-MIB
  - ARISTA-QUEUE-MIB
  - BGP4-MIB
  - CISCO-MEMORY-POOL-MIB
  - CISCO-PROCESS-MIB
  - HOST-RESOURCES-MIB
  - IF-MIB
  - OSPF-MIB
  - PowerNet-MIB_UPS
```

Required settings are outlined in detail in our documentation for [devices](/docs/network-performance-monitoring/advanced/advanced-config/#devices) and [global blocks](/docs/network-performance-monitoring/advanced/advanced-config/#global).
</Collapser>

</CollapserGroup>

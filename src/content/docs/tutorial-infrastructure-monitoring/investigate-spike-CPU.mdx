---
title: Investigate a spike in CPU
metaDescription: Solve system outages by investigating resource bottlenecks across your system infrastructure.
---

import cpuSpike from 'images/infrastructure_screenshot-full_cpu.webp'

import hostProcesses from 'images/infrastructure_screenshot-full_process.webp'

import checkLoad from 'images/infrastructure_screenshot-crop_load.webp'

Now that you understand how to explore your data, it's time to learn how to dig deeper into your data so you can move through the troubleshooting process. Let's say that you've been notified that there's a problem with the underlying infrastructure that supports a team's apps. Using the skills from [Explore host data](/docs/tutorial-infrastructure-monitoring/explore-host-data), you can scope the problem and identify whether or not you need to provision more resources to a given host.   

## Objectives [#objectives]

In this tutorial, you'll learn how to:

* Find the cause of an unexpected load spike
* Determine if you should allocate more resources to a host, or recommend that the notifying team needs to optimize their apps.

## Investigate a sudden spike in load [#spike-load]

If you're focused on host performance, you might not think in terms of apps and services. Still, your hosts support the rest of the system and you may have to make a data-driven decision about whether or not an alerting host needs more resources. How can you use data reporting to New Relic to make that decision?

<Steps>
    <Step>
    ### Determine if there's a problem with your resources
        
Let's assume you have no additional context about the nature of the outage. Your first step is to determine if a change can be correlated to resources at all. Start at the summary page and evaluate your resource-related data: your CPU, memory usage, and disk utilization.

<img
    title="Investigate CPU spike from the summary page"
    alt="A screenshot displaying an infrastructure summary page with high CPU"
    src={cpuSpike}
/>  

Using this screenshot as an example, you can infer that:

* `host-tower-portland` is currently alerting in the critical.
* From the summary table, you can see that the CPU is running hot at 99.84%.
* The metrics graphs show you that this behavior has been ongoing for at least 30 minutes. 

Since this behavior is unexpected, you'll want to dig deeper into that specific host. 

    </Step>
    <Step>
    ### Correlate your data 

Once you click on a host, you'll be taken to a separate page with data specific to your chosen host. At this stage you're digging deeper into any patterns you've identified from the summary page.

Let's see if we can correlate CPU percentage with any other data specific to `host-tower-portland`. 

<img
    title="Check your processes"
    alt="A screenshot displaying an infrastructure summary page with high CPU"
    src={hostProcesses}
/>  

Since we're dealing with CPU percentage, we want to determine if the problem is app related or machine related. To do that, you want to check the **Processes running** table on the host page against the **Latest events** in the sidebar. Based on this screenshot:

* CPU usage is running hot and flatlining near 100%.
* There's a `ruby` process using up 77.34% of your CPU. 
* No events have reported in the last 30 minutes, approximately when the change first occurred. If there were events reporting, you'd look for any change in the machine's config file or whether someone has entered the machine to make changes directly. 

Because you've correlated CPU percentage with a process, you can conclude that an app is hogging your resources rather than the problem coming from the host itself. 

    </Step>
    <Step>
    ### Determine if you should allocate more resources to that app

At this stage you might need to decide if should you allocate more resources to this instance, or if the app itself is mismanaging resources. Let's look at `host-tower-portland` again to investigate if there's a saturation issue.

In the case of troubleshooting a saturation issue, you're correlating network traffic against your infrastructure metrics. In this case, you're expecting the **Network traffic** graph to mirror the metric graphs for CPU usage, memory usage, and so on. If your resources are not responding to an increase in load, then you'd see a departure between the patterns in your metric graphs and the behavior in your Network traffic graph. 

Let's revisit our example and look only at **CPU usage** and **Network traffic**:

<img
    title="Investigate CPU spike from the summary page"
    alt="A screenshot displaying an infrastructure summary page with high CPU"
    src={checkLoad}
/>  

* If this were a saturation problem, you'd see an uptick in Network traffic that slowly degrades over time. This would be because your response time from your app is slowing down since it would need more resources to meet load.
* Network traffic, however, is staying the same. The peaks and troughs are regular without any uptick and steady decline.
* This indicates that the problem is actually with the app, rather than the app needing more resources to meet load.

In this instance, you would not allocate additional resources to the app. Instead, reach out to the owning team and recommend they optimize the offending Ruby process. 

    </Step>
    <Step>
    ### Share with the team


    </Step>
</Steps>

## What's next? [#next]


<UserJourneyControls
    previousStep={{path: "/docs/tutorial-infrastructure-monitoring/explore-host-data", title: "Previous step", body: "Filter down to a set of hosts"}}
    nextStep={{path: "/docs/tutorial-infrastructure-monitoring/collaborate-with-saved-views", title: "Next step", body: "Share your findings across teams"}}
/>
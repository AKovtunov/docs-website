---
title: Develop and implement a parsing strategy
metaDescription: "Develop a parsing strategy for your logs and implement it through grok patterns"
---

Everyone needs different things out of their logs, which is why there isn't one parsing strategy for everyone. For example, one organization might value parsing and storing every value in their logs while another organization might just care about key values such as a customer's name, purchase date, delievery address, or IP address.

## Objectives [#objective]

This doc covers:

* What your parsing strategy should look like
* How to implement your parsing strategy with Grok patterns

## Defining your parsing strategy

Everyone's parsing strategy is different. Below you will find two examples of organizations defining their parsing strategy. One organization will have a bare-bones parsing solution which parses just a few attributes from their logs. The second organization will have a more complex parsing strategy which parses almost all of their log attributes.

### Bare-bones parsing

<SideBySide>
    <Side>
John runs an online bakery selling cookies. Business has boomed recently and he's found himself struggling to keep track of trends in his orders. Thankfully, his payment processor reports logs of every transaction on his site. 

The raw logs are full of info, but John only cares about a few things:

* Tracking which states like which cookie flavors
* Tracking total revenue from individual states

John decides that his parsing strategy will simply be to pull out the attributes that will help him track this data:

* State: `delivery.state`
* Cookie flavor: `cookie.flavor`
* Purchase total: `purchase.total.`

    </Side>
    <Side>

```
{

 "hostname": "inventory-host-1",

 "purchase_date": "10/02/2023",

 "level": "purchase",

 "message": "Completed transaction 584301",

 "cookie.type": "Chocolate",

 "delivery.street": "123 Broad St.,

 "delivery.city": "Portland,

 "delivery.state": "OR",

 "purchase.total": "56.32",

 "purchase.tax": "0"

 "purchase.items": "56.32"

}
```

    </Side>
</SideBySide>


### Complex parsing

<SideBySide>
    <Side>
Emily works for a large warehouse for a digital storefront. Their custom inventory management service creates logs when it encounters an error. These logs are large and full of information.

Unlike the bare-bones implementation above, Emily decides that she should parse out every attribute in the logs. Since these are error logs, any amount of info could be the difference between quick troubleshooting or spending hours trying to troubleshoot the error.

She decides that her organization's parsing strategy will parse out all the log attributes, except the "message" attribute. Emily decides it would be valuable to parse the product number included in the message seperatly so she can query for all logs related to that product.
    </Side>
    <Side>

```
{

 "entity.name": "Inventory Management",

 "entity.type": "SERVICE",

 "fb.input": "tail",

 "fb.source": "nri-agent",

 "hostname": "inventory-host-1",

 "label": "inventory",

 "level": "error",

 "message": "Inventory error: out of memory processing thumbnail for product 7186",

 "plugin.source": "BARE-METAL",

 "plugin.type": "fluent-bit",

 "plugin.version": "1.1.4",

 "span.id": "e2056adfcaf06c15",

 "timestamp": 1598046141558,

 "trace.id": "3c517a62483f66ef5943143b4165c62e"

}
```

    </Side>
</SideBySide>

## Implement parsing strategy

Now that you've developed a parsing strategy, let's create a parsing rule to pull out releveant data within your logs for easier querying and accessability.

To parse your logs:

<SideBySide>
    <Side>

1. From **Manage Data** on the left nav of the logs UI, click **Parsing**, then click **Create parsing rule**.
2. Enter a name for the new parsing rule.
3. Select an existing field to parse (the default is `message`), or enter a new field name.
4. Enter a valid NRQL `WHERE` clause to match the logs you want to parse. 
5. Select a matching log if one exists, or click on the paste log tab to paste in a sample log.
6. Enter the parsing rule and validate it's working by viewing the results in the **Output** section. (See example below)
7. Enable and save the custom parsing rule.

    </Side>
    <Side>

<img
    title="log-parsing"
    alt="An image displaying New Relic's log parsing UI"
    src={logsParsing}
/>

    </Side>
</SideBySide>

The two tabs below guide you through an example of implementing both the parsing strategies mentioned at the start of this doc. They each follow similar steps, but the complex parsing example contains info on parsing a single attribute into two. We recommend you read through both to understand how Grok patterns are developed to implement your log parsing strategy.

<Tabs>
	<TabsBar>
        <TabsBarItem id="1">
            Bare-bones parsing 
        </TabsBarItem>
        <TabsBarItem id="2">
            Complex parsing
        </TabsBarItem>
    </TabsBar>

    <TabsPages>
        <TabsPageItem id="1">

## Bare-bones parsing implementation
Let's work with the bare-bones cookie store example we used earlier in this doc. You have logs that follow this pattern:

```
{

 "hostname": "inventory-host-1",

 "purchase_date": "10/02/2023",

 "level": "purchase",

 "message": "Completed transaction 584301",

 "cookie.type": "Chocolate",

 "delivery.street": "123 Broad St.,

 "delivery.city": "Portland,

 "delivery.state": "OR",

 "purchase.total": "56.32",

 "purchase.tax": "0"

 "purchase.items": "56.32"

}
```

You want to pull out the following attributes:

* State: `delivery.state`
* Cookie flavor: `cookie.flavor`
* Purchase total: `purchase.total.`

Parsing rules are built using Grok, which uses the following pattern: `%{SYNTAX:SEMANTIC}`. `SYNTAX` is the pattern used to find the text and `SEMANTIC` is the identifier or attribute given to the matched result.

In this case, our parsing rule would look like:

```
"cookie.type":%{DATA:cookie_type} "delivery.state":%{DATA:delivery_state} "purchase.total":%{DATA:purchase_total}
```

Once the parsing rule is created with the pattern above, it will return logs in the following manner:

```
{
    "cookie_type": "Chocolate",
    "delivery_state": "OR",
    "purchase_total": "56.32",
}
```



        </TabsPageItem>
        <TabsPageItem id="2">

## Complex parsing implementation

Let's work with the complex inventory management example we used earlier in this doc. You have logs that follow this pattern:

```
{

 "entity.name": "Inventory Management",

 "entity.type": "SERVICE",

 "fb.input": "tail",

 "fb.source": "nri-agent",

 "hostname": "inventory-host-1",

 "label": "inventory",

 "level": "error",

 "message": "Inventory error: out of memory processing thumbnail for product 7186",

 "plugin.source": "BARE-METAL",

 "plugin.type": "fluent-bit",

 "plugin.version": "1.1.4",

 "span.id": "e2056adfcaf06c15",

 "timestamp": 1598046141558,

 "trace.id": "3c517a62483f66ef5943143b4165c62e"

}
```

You want to pull out the following attributes:

 * `entity_name`
 * `entity_type`
 * `fb_input`
 * `fb_source`
 * `hostname`
 * `label`
 * `level`
 * `message`
 * `product_id` - note that this attribute is found within the error message of the log. You'll have to parse this out seperatly.
 * `plugin_source`
 * `plugin_type`
 * `plugin_version`
 * `span_id`
 * `timestamp`
 * `trace_id`

Parsing rules are built using Grok, which uses the following pattern: `%{SYNTAX:SEMANTIC}`. `SYNTAX` is the pattern used to find the text and `SEMANTIC` is the identifier or attribute given to the matched result.

In this case, our parsing rule would look like:

```
 "entity.name": %{DATA:entity.name} "entity.type": %{DATA:entity.type} "fb.input": %{DATA:fb.input} "fb.source": %{DATA:fb.source} "hostname": %{DATA:hostname} "label": %{DATA:label} "level": %{DATA:level} Inventory error: %{DATA:error_message} for product %{INT:product_id} "plugin.source": %{DATA:plugin.source} "plugin.type": %{DATA:plugin.type} "plugin.version": %{DATA:plugin.version} "span.id": %{DATA:span.id} "timestamp": %{INT:timestamp} "trace.id": %{DATA:trace.id}
```

In the pattern, most attributes are parsed by finding the attribute name in the log (`entity.name`) and using a Grok pattern to pull out the actual value and tie it to a new attribute name (`%{DATA:entity.name}`). 

We parsed out `product_id` differently. For that we parsed through the `message` log attribute and split it into `error_message` and `product_id`:

```
Inventory error: %{DATA:error_message} for product %{INT:product_id}
```


Once the parsing rule is created with the pattern above, it will return logs in the following manner:

```
{

 "entity_name": "Inventory Management",

 "entity_type": "SERVICE",

 "fb_input": "tail",

 "fb_source": "nri-agent",

 "hostname": "inventory-host-1",

 "label": "inventory",

 "level": "error",

 "error_message": "out of memory processing thumbnail for product",

 "product_id": "7186"

 "plugin_source": "BARE-METAL",

 "plugin_type": "fluent-bit",

 "plugin_version": "1.1.4",

 "span_id": "e2056adfcaf06c15",

 "timestamp": 1598046141558,

 "trace_id": "3c517a62483f66ef5943143b4165c62e"

}
```

        </TabsPageItem>
    </TabsPages>
</Tabs>

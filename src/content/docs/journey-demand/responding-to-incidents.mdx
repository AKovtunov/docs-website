---
title: "Responding to incidents on gameday"
metaDescription: "Elephant."
---

The previous docs walked you through service level planning, the art of creating quality alerts, how to organize your data with workloads, and an option for allocating resources for your infrastructure needs. These tools are part of the picture when you're planning for a peak demand event. But what about the day of? How do you use New Relic to drill deeper? 

This part of the tutorial demonstrates one journey for finding root cause, using the tools from this tutorial combined with other out of the box capabilities. You'll see how you can take a big picture problem, then drill in by following the data through New Relic.

## You receive an alert [#alert]

You've received an alert that your Apdex score has fallen below 0.5 on something called `Billing Service`. You know this is a problem because Apdex measures response time against error rate, and it's a good indicator for the success of your application. In this case, `Billing Service` is failing. Time to drill deeper.

[ELEPHANT]

While other incidents exist with your CPU and memory, you've anticipated this kind of stress from your performance planning period. Demand has peaked, so stress on your CPU and memory is expected. That said, your Apdex score receiving 1 error in under 5 minutes immediately affects your customers. From planning, you've determined, too, that this transaction is a critical one. You choose to start here.

## Track affected entities [#track]

After you click through the [policy?] that alerted you, scroll to the **Impacted entities** pane. You see that Billing Service has affected your Shipping Service and have an idea of the scope of the problem, but you're not any closer to knowing the root cause. You have two paths you can take, either investigating your error rates or response time. We recommend looking at your error rate first as it's a quick and easy path to eliminate if you're uncertain.

* If it's an error rate, New Relic will provide short descriptions about why you're failing out.
* If it's related to response time, you could have multiple causes to start with. Is it a resource limitation? Is it failing out because of an external dependency that's not sending a response? 

[ELEPHANT]

After clicking the **See errors** button, you're taken to a waterfall view of error groups. In this case, you notice that some event happened with `exceptions:SystemError` that triggered multiple reporting errors. Clicking through, you're taken to an **Error group summary** of this event. 

## Follow the trace [#trace]

The **Error group summary** provides context. You can view occurences of the error, or stack trace and distributed trace data, or view your logs. You have some flexibility about what to look at first and what you want to prioritize. One possible journey on this page would look at:

1. In the stack trace pane, you see that billing service tried to communicate with a shipping submission. 
2. You notice some distributed tracing information, which implies a service external to your system is involved.
3. Your logs info whittles at the specificity of the error. You notice a log that says `




---
title: Simplify kubernetes layers with New Relic
---

import k8sDiagramContext from 'images/tutorials_diagram_kubernetes-overview.webp'

import tutorialOverviewdashboard from 'images/tutorial_screenshot-full_overview-dashboard.webp'

import tutorialOverviewDeployments from 'images/tutorial_screenshot-full_overview-deployments.webp'

import tutorialOverviewFailed from 'images/tutorial_screenshot-crop_failed-pods.webp'

import tutorialAPMOverview from 'images/tutorial_screenshot-full_apmK8s.webp'

import tutorialAPMPerformance from 'images/tutorial_screenshot-full_apm-k8s-performance.webp'

Understanding the inner workings of your Kubernetes system, specifically how all the different functions of the system come together, is inherently complex. Let's review what makes up a Kubernetes system and then dive into how New Relic can help monitor and understand each part.

## Break it apart to understand

To gain a better grasp of a Kubernetes system, let's break it down into distinct layers and explore how New Relic can help you comprehend each one effectively.

<img
    title="k8sDiagramContext"
    alt="an image showing an abstracted view of a kubernetes system. This includes pods, apps, and clusters"
    src={k8sDiagramContext}
/>

We'll discuss a Kubernetes system in three key sections:

  * **The Cluster**: This represents the entire Kubernetes system. Imagine a vast bakery comprised of many ovens each with its own set of bakers. The cluster contain multiple deployments, which in turn house many pods, with each pod containing its individual services and applications.

  * **The Orchestrated**: These are the core elements of a Kubernetes system. Think of them as the individual baking stations within the bakery. Orchestrated components consist of deployments that, in turn, house pods, working together in harmony.

  * **The Services and Applications**: Services and applications are the workhorses of the Kubernetes system. Think of them as the indivdual bakers running each oven. Within a Kubernetes system each pod houses one or more services and applications. The services and applocations provide the essential functionality that drives the system. This could be computation, a web application, or any other application.

It's important to note that these sections interalate with each other. The cluster contains multiple orchestrated layers, and each orchestrated section consists of multiple service and application layers.

##  Understand and monitor the cluster layer

Imagine your Kubernetes cluster as an expansive bakery again. The bakery is equipped with multiple ovens and skilled bakers staioned on each oven. If your bakery has only two or three ovens and a few bakers, it's manageable to oversee each oven unit personally. However, when we scale up with dozens or hundreds of bakers and ovens, keeping track of every single unit becomes a near-impossible task.

Similarly, in a large Kubernetes system, with numerous deployments and pods, manually monitoring each component becomes impractical. New Relic offers a more efficient approach to oversee the entire system's health and receive timely alerts when issues arise.

The following steps guide your through a general monitoring strategy for your cluster:

<Steps>
    <Step>
### Navigate to the overview dashboard

Go to **[one.newrelic.com > All capabilities](https://one.newrelic.com/all-capabilities) > Kubernetes > Overview Dashboard**. 
    </Step>
    <Step>

### Triage your cluster

The Kubernetes overview dashboard shows your high level data about your cluster. You can find general data such as the count of pods and services, but more importantly you can find data about the health of your cluster such as the percent of pods running, the count of failed pods, the number of container restarts, and more. Be sure to scroll down to see all the graphs available to you.

<img
    title="tutorialOverviewdashboard"
    alt="The main overview dashboard for the kubernetes capability"
    src={tutorialOverviewdashboard}
/>

Use this dashboard to gauge the general health of your cluster. Here are a few things to look for:

* Red or yellow tiles: think of yellow tiles as warnings to keep an eye on what it monitors. For example, if you have 2 unhealthy deployments you should take note and possibly plan to troubleshoot those deployments. Think of red tiles as critical alerts. These aren't necessarily failures in your system, but you should prioritize addressing them as immediately as possible.  
* Anomalous spikes in graphs: there are various graphs that show things such as pending pods over time or even memory utilization over time. Spike are fairly normal, such as the spikes in the **Kubernetes Warning Events by Reason** graph in the screenshot above. These spikes happen regularly about every 5 minutes so they are no cause for concern. Look for spikes that happen outside of regular patterns or spike in a much larger magnitude than normal. 
* Node readiness: observe whether nodes in the cluster are ready and able to host pods. Ensure that your cluster's infrastructure is prepared to handle workloads without any bottlenecks.
* Resource count insights: keep a close eye on the number of pods, containers, nodes, or other Kubernetes resources within the cluster. While you won't always find something actionable, monitoring resource utilization allows you to plan for future scaling.

Use the time selector in the top left of the page to see your data across time ranges to verify any troubling data isn't just random or to triage across a longer timeframe. 
    </Step>
</Steps>

## Understand and monitor the orchestrated layer

Continuing with our bakery analogy, the orchestrated layer is the baking stations within the bakery. Each station houses a set of ovens that work together to fulfill specific tasks. Each station might be designated to have three ovens running at all times. If an oven fails, the station will fire up a new oven to keep up with expectations.

In a Kubernetes system, deployments have various specifications. For example, a deplyoment might be specified to always run four instances of an application in individual containers. The deployment will spin up pods containing that application until it meets that quota. If a pod were to fail, it would spin up a new one to continue to meet the specified  .


The following steps guide you through a general strategy to monitor your deployments:

<Steps>
    <Step>
### Navigate to the overview dashboard

Go to **[one.newrelic.com > All capabilities](https://one.newrelic.com/all-capabilities) > Kubernetes > Overview Dashboard**.         
    </Step>
    <Step>
### Triage your deployments

Take a look at the unhealthy deployment tile and the deployments tile. Compare the two to measure the percentage of unhealthy deployments in your cluster. Unhealthy deployments are deployments with missing or unavailable pods. This usually means that the deployment was unable to spin up those pods. Let's take a close look.

<img
    title="tutorialOverviewdashboard"
    alt="The main overview dashboard for the kubernetes capability"
    src={tutorialOverviewDeployments}
/>

    </Step>
    <Step>
        
### Identify pending and failed pods

Scroll down a bit and find the **Pending and Failed Pods** table. This table will show you all the pods that have failed or are stuck pending for whatever reason. It's normal that pods fail at to a certain degree depending on the baseline health of your system. What you're looking for is pods that repeatedly fail. Scroll down the chart as needed. Once you've identified which pods have are failing regularly, troubleshoot the deployment configs for those pods.

<img
    title="tutorialOverviewFailed"
    alt="The main overview dashboard for the kubernetes capability focusing on the failed pods section"
    src={tutorialOverviewFailed}
/>

    </Step>
</Steps>

### Understand and monitor the service and application layer

In your bakery, a baker runs each individual oven. These bakers are the heart of the system, providing the actual value â€” the bread!. 

In your kubernetes system, each pod contains services and applications that provide the actual functionality that your kubernetes system supports. This could be computation, a web app, or anything inbetween.


The following steps guide you through a general strategy to monitor your applications and services:

<Steps>
    <Step>
### Navigate to the APM Kubernetes dashboard

Go to **[one.newrelic.com > All capabilities](https://one.newrelic.com/all-capabilities) > APM & Services > select your application > Kubernetes**.     
    </Step>
    <Step>
### Triage your application

This page shows you a general overview of all the instances of that application within your Kubernetes cluster. There are various useful charts and graphs here, but take a close look at the activity stream on the far right. This will highlight any important performance events of those applications. Increase the time range as necessary to gather a full view of the performance history.

 Only you can decide what is acceptable, but multiple events a day indicates you could improve performance. For example, in the image above there are multiple Apdex warnings within just a few hours. [Apdex warnings indicate a degraded user experience](/docs/apm/new-relic-apm/apdex/apdex-measure-user-satisfaction/). 

<img
    title="tutorialAPMOverview"
    alt="The main overview dashboard for an APM service in a Kubernetes cluster"
    src={tutorialAPMOverview}
/>
    </Step>
    <Step>
### Identify the cause of performance issues 

Scroll down until you see four graphs. On the top left of each graph, select the dropdown and set the graphs to the following:
* Service error rate
* Service throughput
* Service response time
* Container restart count

<img
    title="tutorialAPMOverview"
    alt="The main overview dashboard for an APM service in a Kubernetes cluster"
    src={tutorialAPMPerformance}
/>

The first three graphs will show you the health of your applications. The restart count graph helps you correlate if your performance has any affect on your general pod health.

In the screenshot above we can note a few things:
* The error rate stays at zero, which means errors are not affecting performance.
* The service throughput spikes extremely often
* The service response time regularly fluctutes close to 70ms 
* The container restart graph stays at zero, which means the performance of my applications is not causing critical failures in my cluster.

In this case, you can identify throughput and response time as the key indicators of your degraded performance. There are many ways to solve these from optimizing the application itself or just throwing more CPU power at the containers hosting the application.

    </Step>
</Steps>

## What's next?

Now that you've learned how to use New Relic to monitor Kubernetes, you can explore our other tutorials:


* Is your app running slow? Learn how to triage and diagnose latency in your app with our [My app is slow](docs/tutorial-app-slow/root-causes) tutorial.
* If you have a peak demand day coming up, learn how New Relic can help you with [capacity planning](/docs/tutorial-peak-demand/get-started).
* Do you want to create high quality alerts? Our [alerts tutorial](/docs/tutorial-create-alerts/create-new-relic-alerts/) can help you set up an alerting system.  

<UserJourneyControls
    previousStep={{path: "docs/tutorial-kubernetes-learn/tutorial-k8s-intro", title: "Previous step", body: "Learn about Kubernetes monitoring."}}
/>
